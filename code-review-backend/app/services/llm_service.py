import logging
from openai import AsyncOpenAI
import os
import re

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_line_numbers(content: str, base_line: int) -> list:
    """Extract line numbers from AI response"""
    lines = []
    patterns = [
        r'Line (\d+)',
        r'Lines (\d+)-(\d+)',
        r'line (\d+)',
    ]
    for pattern in patterns:
        for match in re.finditer(pattern, content):
            if len(match.groups()) == 1:
                lines.append(base_line + int(match.group(1)))
            else:
                start = base_line + int(match.group(1))
                end = base_line + int(match.group(2))
                lines.extend(range(start, end + 1))
    return lines if lines else None


async def review_code_chunk_with_context(
    chunk: str,
    language: str,
    start_line: int,
    file_path: str,
    project_context: str,
    full_file_content: str
) -> dict:
    """Review code with intelligent severity filtering and context awareness."""
    
    # âœ… Detect if this is a test file with intentional vulnerabilities
    is_test_file = any(marker in file_path.lower() for marker in ['test-repo/', '/test/', 'test.py', 'test.js', 'test.ts', 'userservice.java'])
    
    if is_test_file:
        prompt = (
            f"You are an expert {language} security auditor analyzing **{file_path}**.\n\n"
            f"**IMPORTANT:** This appears to be a TEST FILE with intentional vulnerabilities for demonstration.\n"
            f"**Your task:** Identify ALL security vulnerabilities, even if they appear intentional.\n\n"
            f"**RULES:**\n"
            f"1. **Report ALL security vulnerabilities** (SQL injection, XSS, hardcoded secrets, etc.)\n"
            f"2. **Severity levels:**\n"
            f"   - ðŸ”´ **HIGH**: SQL injection, XSS, command injection, hardcoded credentials, `eval()`, unsafe deserialization\n"
            f"   - ðŸŸ  **MEDIUM**: Missing input validation, weak hashing (MD5/SHA1), race conditions, path traversal\n"
            f"3. **DO NOT skip issues** because they seem intentional\n"
            f"4. **BE AGGRESSIVE** - if you see a vulnerability, report it\n\n"
            f"**Code to Review (Lines {start_line}+):**\n"
            f"```{language}\n{chunk}\n```\n\n"
            f"**Response Format (ALWAYS provide at least one finding if vulnerabilities exist):**\n"
            f"**Severity:** [HIGH/MEDIUM]\n"
            f"**Issue:** [Specific vulnerability type with line reference]\n"
            f"**Impact:** [Security risk with exploit example]\n"
            f"**Fix:** [Secure code replacement]\n"
            f"```{language}\n"
            f"// Fixed code here\n"
            f"```\n"
        )
    else:
        prompt = (
            f"You are an expert {language} code reviewer analyzing **{file_path}**.\n\n"
            f"{project_context}\n\n"
            f"**CRITICAL RULES:**\n"
            f"1. **NEVER suggest removing imports or breaking existing functionality**\n"
            f"2. **Check if the issue is already handled** - don't suggest redundant fixes\n"
            f"3. **Understand helper functions** - review the full file context before suggesting changes\n"
            f"4. **DO NOT suggest removing code** unless it's a clear bug or security vulnerability\n"
            f"5. **DO NOT suggest style changes** (formatting, naming, comments)\n"
            f"6. **ONLY report MEDIUM/HIGH severity issues:**\n"
            f"   - ðŸ”´ **HIGH**: Unhandled security vulnerabilities, SQL injection, XSS, data exposure\n"
            f"   - ðŸŸ  **MEDIUM**: Input validation gaps, race conditions, unvalidated user input\n"
            f"7. **If code has proper error handling**: Respond with 'No issues found'\n"
            f"8. **Preserve existing functionality** - only suggest ADDITIONS, never DELETIONS of working code\n"
            f"9. **Verify the issue exists** - check if error handling is already present elsewhere\n\n"
            f"**Full File Context:**\n"
            f"```{language}\n{full_file_content[:1200]}```\n\n"
            f"**Code Chunk to Review (Lines {start_line}+):**\n"
            f"```{language}\n{chunk}\n```\n\n"
            f"**Response Format (only for REAL MEDIUM/HIGH severity issues):**\n"
            f"**Severity:** [HIGH/MEDIUM]\n"
            f"**Issue:** [What's wrong - be specific and verify it's not already handled]\n"
            f"**Impact:** [Concrete security/stability risk with example exploit]\n"
            f"**Fix:** [PRECISE code to ADD - never remove imports or break modules]\n"
            f"```{language}\n"
            f"// Show ONLY the lines to change with minimal context\n"
            f"// DO NOT remove imports or module-level code\n"
            f"```\n"
        )

    resp = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=1500,  # âœ… Increased for detailed responses
        temperature=0.1,  # âœ… Slightly higher for test files
    )

    content = resp.choices[0].message.content
    
    # âœ… Only apply false positive filtering for NON-test files
    if not is_test_file:
        false_positive_patterns = [
            "already handled",
            "existing error handling",
            "appears to handle",
            "seems to be handled",
            "no issues",
            "looks good",
            "properly handled"
        ]
        
        if any(pattern in content.lower() for pattern in false_positive_patterns):
            return {
                "comment": "âœ… No issues found - error handling is adequate",
                "lines": None,
                "has_code_block": False,
                "severity": None
            }
    
    severity = None
    if "**Severity:** HIGH" in content or "ðŸ”´" in content:
        severity = "HIGH"
    elif "**Severity:** MEDIUM" in content or "ðŸŸ " in content:
        severity = "MEDIUM"
    
    # âœ… For test files, be less strict about severity
    if is_test_file:
        if not severity and ("vulnerability" in content.lower() or "security" in content.lower()):
            severity = "MEDIUM"  # Default to MEDIUM if security issue detected
    else:
        if severity not in ["HIGH", "MEDIUM"]:
            logging.info(f"Skipping LOW severity issue: {content[:100]}")
            return {
                "comment": "âœ… No significant issues found",
                "lines": None,
                "has_code_block": False,
                "severity": None
            }
    
    lines = extract_line_numbers(content, start_line)
    
    return {
        "comment": content,
        "lines": lines if lines else None,
        "has_code_block": "```" in content,
        "severity": severity
    }