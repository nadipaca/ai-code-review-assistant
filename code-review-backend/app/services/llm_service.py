import logging
from openai import AsyncOpenAI
import os
import re
import difflib

client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Configure detailed logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def parse_individual_issues(llm_response: str, original_code: str, file_path: str) -> list:
    """
    Parse LLM response and generate individual issues with proper diffs including context.
    Each issue contains: comment, diff, highlighted_lines
    """
    issues = []
    
    # Split by horizontal rules or numbered issues
    sections = re.split(r'\n---\n|\n\d+\.\s+', llm_response)
        
    for section in sections[1:]:  # Skip first empty section
        if not section.strip():
            continue
        
        # Extract severity
        severity_match = re.search(r'\*\*(HIGH|MEDIUM|LOW)\*\*', llm_response)
        severity = severity_match.group(1) if severity_match else "MEDIUM"
        
        # Extract comment/description
        comment_match = re.search(r'\*\*Issue:\*\*\s*([^\n*]+)', section)
        comment = comment_match.group(1).strip() if comment_match else section.strip()[:200]
        
        # Extract line numbers
        line_numbers = []
        for match in re.finditer(r'(?:Line|Lines)\s+(\d+)(?:-(\d+))?', section):
            if match.group(2):
                line_numbers.extend(range(int(match.group(1)), int(match.group(2)) + 1))
            else:
                line_numbers.append(int(match.group(1)))
        
        # Extract fixed code
        code_blocks = re.findall(r'```[\w]*\n(.*?)\n```', section, re.DOTALL)
        fixed_code = code_blocks[0].strip() if code_blocks else ""
        
        # ‚úÖ Generate diff with CONTEXT LINES
        diff = ""
        if line_numbers and fixed_code:
            original_lines = original_code.split('\n')
            
            # ‚úÖ Include context: 5 lines before and after
            context_before = 5
            context_after = 5
            
            start_line = max(0, min(line_numbers) - context_before - 1)
            end_line = min(len(original_lines), max(line_numbers) + context_after)
            
            # Extract original snippet with context
            original_snippet = '\n'.join(original_lines[start_line:end_line])
            
            # Create modified snippet (replace changed lines, keep context)
            modified_lines = original_lines.copy()
            change_start = min(line_numbers) - 1
            change_end = max(line_numbers)
            
            # Replace the changed section
            modified_lines[change_start:change_end] = fixed_code.split('\n')
            modified_snippet = '\n'.join(modified_lines[start_line:start_line + len(original_snippet.split('\n'))])
            
            # Generate unified diff
            diff_lines = list(difflib.unified_diff(
                original_snippet.splitlines(keepends=True),
                modified_snippet.splitlines(keepends=True),
                fromfile=f"a/{file_path}",
                tofile=f"b/{file_path}",
                lineterm='',
                n=5  # ‚úÖ 5 context lines
            ))
            diff = ''.join(diff_lines)
        
        issues.append({
            "comment": comment,
            "diff": diff,
            "highlighted_lines": line_numbers[:10] if line_numbers else [],
            "severity": severity,
            "has_code_block": True
        })
    
    return issues if issues else []

def extract_line_numbers(content: str, base_line: int) -> list:
    """Extract line numbers from AI response"""
    lines = []
    patterns = [
        r'Line (\d+)',
        r'Lines (\d+)-(\d+)',
        r'line (\d+)',
    ]
    for pattern in patterns:
        for match in re.finditer(pattern, content):
            if len(match.groups()) == 1:
                lines.append(base_line + int(match.group(1)))
            else:
                start = base_line + int(match.group(1))
                end = base_line + int(match.group(2))
                lines.extend(range(start, end + 1))
    return lines if lines else None


async def review_code_chunk_with_context(
    chunk: str,
    language: str,
    start_line: int,
    file_path: str,
    project_context: str,
    full_file_content: str
) -> dict:
    """Review code with intelligent severity filtering and context awareness."""
    
    # Detect if this is a test file with intentional vulnerabilities
    is_test_file = any(marker in file_path.lower() for marker in ['test-repo/', '/test/', 'test.py', 'test.js', 'test.ts', 'userservice.java'])
    
    logging.info(f"{'='*80}")
    logging.info(f"üîç REVIEWING: {file_path}")
    logging.info(f"üìÅ Is test file: {is_test_file}")
    logging.info(f"üìù Language: {language}")
    logging.info(f"üìè Chunk length: {len(chunk)} chars")
    logging.info(f"üî¢ Starting at line: {start_line}")
    
    if is_test_file:
        prompt = (
            f"You are an expert {language} security auditor analyzing **{file_path}**.\n\n"
            f"**IMPORTANT:** This appears to be a TEST FILE with intentional vulnerabilities for demonstration.\n"
            f"**Your task:** Identify ALL security vulnerabilities, even if they appear intentional.\n\n"
            f"**RULES:**\n"
            f"1. **Report ALL security vulnerabilities** (SQL injection, XSS, hardcoded secrets, etc.)\n"
            f"2. **Severity levels:**\n"
            f"   - üî¥ **HIGH**: SQL injection, XSS, command injection, hardcoded credentials, `eval()`, unsafe deserialization\n"
            f"   - üü† **MEDIUM**: Missing input validation, weak hashing (MD5/SHA1), race conditions, path traversal\n"
            f"3. **DO NOT skip issues** because they seem intentional\n"
            f"4. **BE AGGRESSIVE** - if you see a vulnerability, report it\n\n"
            f"**Code to Review (Lines {start_line}+):**\n"
            f"```{language}\n{chunk}\n```\n\n"
            f"**Response Format (ALWAYS provide at least one finding if vulnerabilities exist):**\n"
            f"**Severity:** [HIGH/MEDIUM]\n"
            f"**Issue:** [Specific vulnerability type with line reference]\n"
            f"**Impact:** [Security risk with exploit example]\n"
            f"**Fix:** [Secure code replacement]\n"
            f"```{language}\n"
            f"// Fixed code here\n"
            f"```\n"
        )
    else:
        prompt = (
            f"You are an expert {language} code reviewer analyzing **{file_path}**.\n\n"
            f"{project_context}\n\n"
            f"**CRITICAL RULES:**\n"
            f"1. **NEVER suggest removing imports or breaking existing functionality**\n"
            f"2. **Check if the issue is already handled** - don't suggest redundant fixes\n"
            f"3. **Understand helper functions** - review the full file context before suggesting changes\n"
            f"4. **DO NOT suggest removing code** unless it's a clear bug or security vulnerability\n"
            f"5. **DO NOT suggest style changes** (formatting, naming, comments)\n"
            f"6. **ONLY report MEDIUM/HIGH severity issues:**\n"
            f"   - üî¥ **HIGH**: Unhandled security vulnerabilities, SQL injection, XSS, data exposure\n"
            f"   - üü† **MEDIUM**: Input validation gaps, race conditions, unvalidated user input\n"
            f"7. **If code has proper error handling**: Respond with 'No issues found'\n"
            f"8. **Preserve existing functionality** - only suggest ADDITIONS, never DELETIONS of working code\n"
            f"9. **Verify the issue exists** - check if error handling is already present elsewhere\n\n"
            f"**Full File Context:**\n"
            f"```{language}\n{full_file_content[:1200]}```\n\n"
            f"**Code Chunk to Review (Lines {start_line}+):**\n"
            f"```{language}\n{chunk}\n```\n\n"
            f"**Response Format (only for REAL MEDIUM/HIGH severity issues):**\n"
            f"**Severity:** [HIGH/MEDIUM]\n"
            f"**Issue:** [What's wrong - be specific and verify it's not already handled]\n"
            f"**Impact:** [Concrete security/stability risk with example exploit]\n"
            f"**Fix:** [PRECISE code to ADD - never remove imports or break modules]\n"
            f"```{language}\n"
            f"// Show ONLY the lines to change with minimal context\n"
            f"// DO NOT remove imports or module-level code\n"
            f"```\n"
        )

    resp = await client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=1500,
        temperature=0.1,
    )

    content = resp.choices[0].message.content
    
    logging.info(f"üì• RAW LLM RESPONSE ({len(content)} chars)")
    
    # Only apply false positive filtering for NON-test files
    if not is_test_file:
        false_positive_patterns = [
            "already handled",
            "existing error handling",
            "appears to handle",
            "seems to be handled",
            "no issues",
            "looks good",
            "properly handled"
        ]
        
        if any(pattern in content.lower() for pattern in false_positive_patterns):
            logging.info(f"‚ùå FILTERED OUT: False positive detected")
            return {
                "comment": "‚úÖ No issues found - error handling is adequate",
                "lines": None,
                "has_code_block": False,
                "severity": None
            }
    
    severity = None
    if "**Severity:** HIGH" in content or "üî¥" in content:
        severity = "HIGH"
    elif "**Severity:** MEDIUM" in content or "üü†" in content:
        severity = "MEDIUM"
    
    # For test files, be less strict about severity
    if is_test_file:
        if not severity and ("vulnerability" in content.lower() or "security" in content.lower()):
            severity = "MEDIUM"
            logging.warning(f"‚ö†Ô∏è Test file: Defaulting to MEDIUM severity")
    else:
        if severity not in ["HIGH", "MEDIUM"]:
            logging.info(f"‚ùå FILTERED OUT: Severity not HIGH/MEDIUM (was: {severity})")
            return {
                "comment": "‚úÖ No significant issues found",
                "lines": None,
                "has_code_block": False,
                "severity": None
            }
    
    lines = extract_line_numbers(content, start_line)
    
    result = {
        "comment": content,
        "lines": lines if lines else None,
        "has_code_block": "```" in content,
        "severity": severity
    }
    
    logging.info(f"‚úÖ RESULT: Severity={severity}, Lines={lines}, HasCode={'```' in content}")
    logging.info(f"{'='*80}\n")
    
    return result